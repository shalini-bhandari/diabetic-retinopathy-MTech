{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00f98e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca34283",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_IMAGE_DIR = '../data/full_dataset/train_images/'\n",
    "CSV_PATH = '../data/full_dataset/train.csv'\n",
    "SUBSET_DIR = '../data/subset/'\n",
    "MODELS_DIR = '../models/'\n",
    "RESULTS_DIR = '../results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf5365d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "SAMPLES_PER_CLASS = 250\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "\n",
    "# Create necessary directories if they don't exist\n",
    "os.makedirs(SUBSET_DIR, exist_ok=True)\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae59fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Step 3: Creating Balanced Data Subset ---\")\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "balanced_df = df.groupby('diagnosis').apply(\n",
    "    lambda x: x.sample(SAMPLES_PER_CLASS, random_state=42) if len(x) >= SAMPLES_PER_CLASS else x\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"Copying files for the subset...\")\n",
    "for index, row in balanced_df.iterrows():\n",
    "    image_filename = f\"{row['id_code']}.png\"\n",
    "    source_path = os.path.join(SOURCE_IMAGE_DIR, image_filename)\n",
    "    destination_path = os.path.join(SUBSET_DIR, image_filename)\n",
    "    if not os.path.exists(destination_path): # Avoid re-copying if script is run again\n",
    "        shutil.copyfile(source_path, destination_path)\n",
    "print(f\"Subset created with {len(os.listdir(SUBSET_DIR))} images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2f6240",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Step 4: Preparing DataFrame for Keras Generators ---\")\n",
    "balanced_df['id_code'] = balanced_df['id_code'].astype(str) + '.png'\n",
    "balanced_df['diagnosis'] = balanced_df['diagnosis'].astype(str)\n",
    "train_df, val_df = train_test_split(\n",
    "    balanced_df, test_size=0.2, random_state=42, stratify=balanced_df['diagnosis']\n",
    ")\n",
    "print(f\"Training set size: {len(train_df)}, Validation set size: {len(val_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f7fcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Step 5: Setting up Data Generators ---\")\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255., rotation_range=20, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.1, zoom_range=0.1,\n",
    "    horizontal_flip=True, fill_mode='nearest'\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df, directory=SUBSET_DIR, x_col='id_code', y_col='diagnosis',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, class_mode='categorical'\n",
    ")\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df, directory=SUBSET_DIR, x_col='id_code', y_col='diagnosis',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9267e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD THE BASELINE MODEL (MobileNetV2)\n",
    "print(\"\\n--- Step 6: Building the Baseline Model ---\")\n",
    "base_model = MobileNetV2(input_shape=(IMG_SIZE, IMG_SIZE, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(5, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(\"Model built successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cf33af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Step 7: Starting Model Training ---\")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    steps_per_epoch=len(train_df) // BATCH_SIZE,\n",
    "    validation_steps=len(val_df) // BATCH_SIZE\n",
    ")\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5803e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Step 8: Saving Model and Plotting Results ---\")\n",
    "model.save(os.path.join(MODELS_DIR, 'baseline_model.h5'))\n",
    "print(f\"Model saved to {os.path.join(MODELS_DIR, 'baseline_model.h5')}\")\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'baseline_learning_curves.png'))\n",
    "print(f\"Learning curves plot saved to {os.path.join(RESULTS_DIR, 'baseline_learning_curves.png')}\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
